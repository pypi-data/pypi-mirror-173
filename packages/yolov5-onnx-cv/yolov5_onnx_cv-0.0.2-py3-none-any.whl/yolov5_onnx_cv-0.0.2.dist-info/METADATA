Metadata-Version: 2.1
Name: yolov5-onnx-cv
Version: 0.0.2
Summary: YOLOv5 ONNX example by OpenCV DNN.
Author-email: BruceYang <brucefay1115@gmail.com>
License: MIT License        
        Copyright (c) 2020 azzhu        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
Project-URL: Homepage, https://github.com/brucefay1115/yolov5_onnx_cv
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: opencv-python (>=4.4.0.40)
Requires-Dist: numpy (>=1.22.0)

YOLOv5-ONNX read example by OpenCV DNN.

If you wanna export to onnx format, please refer:
https://github.com/ultralytics/yolov5


Install package
```
pip install yolov5-onnx-cv
```


Code example:

```python
import numpy as np
from yolov5_onnx_cv import YOLOv5_ONNX_CV
import cv2


# Just inherit YOLOv5_ONNX_CV and define your class_names and class_colors
class YOLOv5(YOLOv5_ONNX_CV):

    # Define coco class names
    class_names = [
        'person', 'bicycle', 'car', 'motorcycle', 'airplane', 
        'bus', 'train', 'truck', 'boat', 'traffic light', 
        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 
        'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 
        'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 
        'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 
        'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 
        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 
        'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 
        'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 
        'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 
        'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 
        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 
        'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
    ]

    # Random to generate colors
    class_colors = [(int(i[0]), int(i[1]), int(i[2])) for i in np.random.randint(256, size=(len(class_names), 3))]


# Simple camera read
def load_capture():
    capture = cv2.VideoCapture(1)
    capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
    return capture


if __name__ == '__main__':
    # Load camera
    capture = load_capture()
    
    # Load checkpoint from any path. (onnx only)
    model = YOLOv5('tests/yolov5s.onnx', (640, 640), 0.5)

    while True:
        # Get camera frame
        success, frame = capture.read()
        if not success:
            print('Open camera fail.')
            break

        # Inference all of output result
        preds = model(frame)
        for pred in preds:
            print(pred.id, pred.name, pred.conf, pred.box)

        # Show labeled box result
        model.show_label_boxes() 
        
        # or you can get labeled box result
        # img = model.get_label_boxes_image()

        # Any key to quit.
        if cv2.waitKey(1) > -1:
            print('finished by user')
            break

    capture.release()

```

Demo example:
![image info](./demo/sample.jpg)
